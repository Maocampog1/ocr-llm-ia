# Taller IA: OCR + LLM (solo GROQ como lo dijo el profe)


import os
import requests
import streamlit as st
from dotenv import load_dotenv
from PIL import Image
import numpy as np
import cv2
import easyocr




# Configuraci√≥n general de la p√°gina
st.set_page_config(page_title="Taller IA: OCR + LLM", page_icon="ü§ñ", layout="centered")

# Encabezado bonitooo
st.markdown(
    """
    <div style="
        background-color:#f0f2f6;
        padding:20px;
        border-radius:15px;
        text-align:center;
        box-shadow: 0 4px 8px rgba(0,0,0,0.1);
        ">
        <h1 style="color:#2c3e50;"> Proyecto IA: OCR + LLM</h1>
        <p style="color:#34495e; font-size:18px;">
        Este trabajo es una demostraci√≥n pr√°ctica donde construimos una aplicaci√≥n web interactiva de principio a fin.<br>
        El objetivo es integrar dos dominios de la Inteligencia Artificial:<br>
        <b>Visi√≥n Artificial</b> para <i>"leer"</i> texto de im√°genes y<br>
        <b>Procesamiento de Lenguaje Natural (NLP)</b> para <i>"entender"</i> y <i>"transformar"</i> ese texto.
        </p>
    </div>
    """,
    unsafe_allow_html=True
)


# Clave GROQ cargada desde .env

load_dotenv()
GROQ_API_KEY = os.getenv("GROQ_API_KEY", "").strip()
if not GROQ_API_KEY:
    st.error("Falta la clave GROQ_API_KEY en tu archivo .env.")
    st.stop()


# Estado de sesi√≥n

if "ocr_text" not in st.session_state:
    st.session_state["ocr_text"] = ""
if "llm_output" not in st.session_state:
    st.session_state["llm_output"] = ""


# OCR con EasyOCR 

@st.cache_resource
def cargar_lector():
    return easyocr.Reader(["es", "en"])

lector = cargar_lector()

def ocr_con_tu_metodo(archivo_imagen, min_conf: float) -> str:
    # Mostrar imagen
    try:
        st.image(Image.open(archivo_imagen), caption="Imagen cargada", use_column_width=True)
    except Exception:
        pass

    # Leer imagen con OpenCV desde el archivo subido por el usuario 
    bytes_data = archivo_imagen.getvalue()
    file_bytes = np.asarray(bytearray(bytes_data), dtype=np.uint8)
    img_cv = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)
    if img_cv is None:
        raise ValueError("No se pudo leer la imagen.")

    img_rgb = cv2.cvtColor(img_cv, cv2.COLOR_BGR2RGB)

   
    resultados = lector.readtext(img_rgb, detail=1)  
    lineas = []
    for r in resultados:
        if isinstance(r, (list, tuple)) and len(r) >= 3:
            _, txt, conf = r
            if isinstance(txt, str) and txt.strip():
                if conf is None or conf >= min_conf:
                    lineas.append(txt.strip())

    if not lineas:  
        lineas = [r[1] for r in resultados if isinstance(r, (list, tuple)) and len(r) >= 2 and isinstance(r[1], str)]

    return "\n".join(lineas).strip()


# Interfaz OCR boni

st.subheader("M√≥dulo 1: Lector de Im√°genes (OCR)")
archivo_imagen = st.file_uploader("Sube una imagen (PNG, JPG o JPEG)", type=["png", "jpg", "jpeg"])
col_a, col_b = st.columns(2)
with col_a:
    min_conf = st.slider("Confianza m√≠nima del OCR", 0.0, 1.0, 0.5, 0.05)
with col_b:
    st.caption("Valores m√°s altos filtran resultados inseguros.")

if archivo_imagen is not None:
    if st.button("Extraer texto (OCR)", use_container_width=True):
        with st.spinner("Extrayendo texto..."):
            try:
                texto = ocr_con_tu_metodo(archivo_imagen, min_conf)
                st.session_state["ocr_text"] = texto
                if texto:
                    st.success("Texto detectado.")
                else:
                    st.warning("No se detect√≥ texto con suficiente confianza.")
            except Exception as e:
                st.error("No se pudo procesar la imagen.")
                st.exception(e)
else:
    st.info("Sube una imagen para comenzar.")

st.text_area("Texto detectado (editable)", key="ocr_text", height=220)


# GROQ LLM Analysis

st.subheader("M√≥dulo 2: An√°lisis con GROQ")

groq_model = st.selectbox(
    "Modelo de GROQ",
    ["llama-3.1-8b-instant", "llama-3.3-70b-versatile"],
    index=0,
)

tarea = st.selectbox(
    "Tarea",
    [
        "Resumir en 3 puntos clave",
        "Identificar entidades principales",
        "Traducir al ingl√©s",
        "Analizar sentimiento (positivo/neutral/negativo)",
    ],
)

col1, col2 = st.columns(2)
with col1:
    temperature = st.slider("Temperature", 0.0, 1.0, 0.3, 0.05)
with col2:
    max_tokens = st.slider("M√°x. tokens", 64, 2048, 512, 32)

texto = st.session_state.get("ocr_text", "").strip()
disabled_btn = not bool(texto)


# Prompts  para GROQ 
#puntos clave, entidades, traducci√≥n, sentimiento
def build_system(tarea_: str) -> str:
    if tarea_ == "Resumir en 3 puntos clave":
        return (
            "Eres un asistente que responde SIEMPRE en espa√±ol. "
            "TAREA: Resume el texto en EXACTAMENTE TRES puntos clave, cada uno en su propia l√≠nea, con guion al inicio y etiqueta.\n"
            "- Punto clave 1: ...\n- Punto clave 2: ...\n- Punto clave 3: ...\n"
            "No incluyas t√≠tulos, introducciones ni texto adicional."
        )
    if tarea_ == "Identificar entidades principales":
        return (
            "Eres un asistente que responde SIEMPRE en espa√±ol. "
            "TAREA: Identifica las identidades/entidades principales del texto y pres√©ntalas en BLOQUES con este formato exacto:\n\n"
            "Nombre de la entidad\n"
            "‚Üí Explicaci√≥n breve en 1‚Äì2 l√≠neas que diga qui√©n/qu√© es y qu√© representa en el texto.\n\n"
            "Deja UNA l√≠nea en blanco entre bloques. No repitas entidades. No agregues encabezados."
        )
    if tarea_ == "Traducir al ingl√©s":
        return (
            "You are a professional translator. "
            "Output ONLY the English translation of the user's text. "
            "No headers, no explanations, no quotes."
        )
   
    return (
        "Eres un asistente que responde SIEMPRE en espa√±ol. "
        "TAREA: Analiza el sentimiento y responde en UNA sola l√≠nea con el formato:\n"
        "Positivo: ...   o   Neutral: ...   o   Negativo: ...\n"
        "Incluye una justificaci√≥n breve. No a√±adas m√°s texto."
    )

def build_user(tarea_: str, txt: str) -> str:
    if tarea_ == "Resumir en 3 puntos clave":
        return f"Resume el siguiente texto en exactamente tres puntos clave, siguiendo el formato con guiones:\n\n{txt}"
    if tarea_ == "Identificar entidades principales":
        return (
            "Identifica las identidades/entidades principales y devu√©lvelas en bloques con el formato indicado "
            "(Nombre en una l√≠nea; en la siguiente l√≠nea, una flecha '‚Üí' seguida de una explicaci√≥n breve en espa√±ol; "
            "una l√≠nea en blanco entre bloques; sin repeticiones):\n\n" + txt
        )
    if tarea_ == "Traducir al ingl√©s":
        return f"Translate this text into natural, fluent English. Output only the translation:\n\n{txt}"
    return f"Analiza el sentimiento (positivo, neutral o negativo) del siguiente texto y justifica brevemente en una sola l√≠nea:\n\n{txt}"

def groq_chat_completion(model, system_msg, user_msg, temp, max_t, api_key):
    url = "https://api.groq.com/openai/v1/chat/completions"
    headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}
    payload = {
        "model": model,
        "messages": [
            {"role": "system", "content": system_msg},
            {"role": "user", "content": user_msg},
        ],
        "temperature": float(temp),
        "max_tokens": int(max_t),
    }
    r = requests.post(url, headers=headers, json=payload, timeout=120)
    r.raise_for_status()
    return r.json()["choices"][0]["message"]["content"]

if st.button("Analizar texto con GROQ", type="primary", use_container_width=True, disabled=disabled_btn):
    if not texto:
        st.warning("Primero extrae o pega texto.")
        st.stop()

    with st.spinner("Consultando GROQ..."):
        try:
            out = groq_chat_completion(
                groq_model,
                build_system(tarea),
                build_user(tarea, texto),
                temperature,
                max_tokens,
                GROQ_API_KEY,
            )
            st.session_state["llm_output"] = out
        except Exception as e:
            st.error("Error al consultar GROQ.")
            st.exception(e)

if st.session_state.get("llm_output"):
    st.success("Respuesta de GROQ")
    st.markdown(st.session_state["llm_output"])



#  Puntos de Discusi√≥n y Reflexi√≥n Final


st.divider()
st.markdown("## Puntos de Discusi√≥n y Reflexi√≥n Final")

with st.container():
    st.markdown("""
###  Diferencias de velocidad entre GROQ y Hugging Face

Durante el desarrollo del proyecto se intent√≥ conectar **Hugging Face** con el modelo `mistralai/Mistral-7B-Instruct-v0.2`,  
pero la API devolv√≠a errores de conexi√≥n y tiempos de respuesta muy altos.  
Por eso, se decidi√≥ trabajar **solo con GROQ**, el cual result√≥ ser mucho **m√°s r√°pido y estable**.

**Explicaci√≥n t√©cnica:**
- GROQ utiliza **infraestructura optimizada en hardware** para ejecutar modelos con **baja latencia**, lo que hace que las respuestas sean casi instant√°neas.
- Hugging Face, en cambio, funciona sobre **servidores compartidos**, lo que puede generar **demoras variables** por uso simult√°neo o ‚Äúcold starts‚Äù.

GROQ ofrece una velocidad superior y una experiencia m√°s fluida,  
mientras que Hugging Face destaca por su variedad de modelos, aunque con tiempos de respuesta menos predecibles.
""")

    st.markdown("""
###  C√≥mo afecta el par√°metro *temperature*

El par√°metro **temperature** controla la **creatividad o precisi√≥n** del modelo:

- **Valores bajos (0.0 ‚Äì 0.3):** respuestas **precisas, repetibles y m√°s l√≥gicas**.  
  Ideal para an√°lisis de sentimiento, resumen estructurado o traducci√≥n literal.
- **Valores altos (0.6 ‚Äì 1.0):** respuestas **m√°s creativas, variadas y con matices**.  
  √ötil para redacciones m√°s libres o generaci√≥n de ideas nuevas.

 En este taller se usaron valores **bajos** para mantener la coherencia y evitar respuestas aleatorias.
""")

    st.markdown("""
###  Importancia del texto extra√≠do por el OCR

La calidad del texto obtenido con OCR fue **clave para el rendimiento del modelo LLM**.

Al inicio, se prob√≥ un m√©todo que no detectaba bien las palabras ni los acentos,  
lo que provocaba que las respuestas del modelo fueran confusas.  
Despu√©s, con la implementaci√≥n de **EasyOCR cacheado y configurado correctamente**,  
el texto se extrajo de forma **m√°s limpia y coherente**, mejorando el an√°lisis del LLM.

Un texto claro y bien estructurado permite al modelo generar resultados m√°s acertados.  
La calidad del OCR define la calidad del an√°lisis final.
""")

    st.markdown("""
###  Qu√© m√°s se podr√≠a integrar en la aplicaci√≥n

Algunas ideas futuras para ampliar esta app ser√≠an:

-  **Clasificaci√≥n autom√°tica** del texto (por tipo: noticia, carta, rese√±a, etc.).  
-  **Preguntas y respuestas** sobre el texto detectado.  
-  **Mejoras gramaticales y ortogr√°ficas** al texto OCR.  
-  **Traducciones a m√°s idiomas** (franc√©s, portugu√©s, alem√°n, etc.).  
-  **Identificaci√≥n de lugares, personas o fechas** dentro del texto.  
-  **Generaci√≥n de texto creativo**, como res√∫menes po√©ticos o narrativos a partir del contenido.  

Estas extensiones podr√≠an hacerse f√°cilmente reutilizando el mismo flujo OCR + LLM y ampliando las opciones de tarea.
""")

#  Conclusi√≥n General
st.divider()
st.markdown("##  Conclusi√≥n General")

st.markdown("""
Este proyecto permiti√≥ **aprender de forma pr√°ctica c√≥mo combinar dos ramas muy diferentes de la Inteligencia Artificial**:  
la **Visi√≥n Artificial (OCR)** para reconocer texto desde im√°genes, y el **Procesamiento de Lenguaje Natural (LLM)** para entender, analizar y transformar ese texto.

Durante el desarrollo se comprendi√≥ c√≥mo funcionan herramientas modernas como **Streamlit**, **EasyOCR** y **GROQ**,  
as√≠ como la importancia de manejar correctamente par√°metros como la *temperature* y la limpieza del texto de entrada.

Adem√°s de ser un proyecto t√©cnico, fue una experiencia **muy interesante y divertida**,  
ya que permiti√≥ integrar conocimientos de programaci√≥n, IA y dise√±o de interfaces en una aplicaci√≥n completa y funcional.

Gracias profe por la clases 
Att: Luis, camilo y Aleja.
""")

